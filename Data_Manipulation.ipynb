{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da6b1898-4803-4c94-9e60-37e9358b934b",
   "metadata": {},
   "source": [
    "# Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531274b3-a978-4a90-89a3-2579afcbb3dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b7ec6c-4726-43a1-8f33-bb73255824d8",
   "metadata": {},
   "outputs": [],
   "source": [
    " # leetcode medium string compression\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbab761-9b0e-4e25-b17e-7b7890a228d4",
   "metadata": {},
   "source": [
    "# Possible Affirm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02d216-047a-44d1-8cef-145bf91d9c6a",
   "metadata": {},
   "source": [
    "# Given a list of strings, find the smallest unique substring for each string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "e07dc640-c217-4e41-9d07-b2223212691e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6, 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['banana', 'cat', 'dog', 'moon', 'sun']"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given a list of strings, find the smallest unique substring for each string.\n",
    "\n",
    "lst = [\"hello\", \"world\", \"apple\", \"banana\", \"cat\", \"dog\", \"moon\", \"sun\", \"rainbow\"]\n",
    "\n",
    "[len(set(x)) for x in lst]\n",
    "\n",
    "def smallest_uniq_substring(lst):\n",
    "    \n",
    "    lst_item_uniq_cnt = [len(set(x)) for x in lst]\n",
    "    min_uniq_cnt = float('inf')\n",
    "    min_uniq_idx = -1\n",
    "    \n",
    "    min_uniq_ct_list = []\n",
    "    min_uniq_idx_list = []\n",
    "\n",
    "    for idx, word in enumerate(lst):\n",
    "        # print('idx',idx)\n",
    "        uniq_char = set(word)\n",
    "        uniq_cnt = len(uniq_char)\n",
    "    \n",
    "        if uniq_cnt < min_uniq_cnt:\n",
    "            min_uniq_cnt = uniq_cnt\n",
    "            \n",
    "    idx_has_min_uniq_ct = [index for index, cnt in enumerate(lst_item_uniq_cnt) if cnt == min_uniq_cnt]\n",
    "    return(idx_has_min_uniq_ct)\n",
    "            \n",
    "index_has_min_uniq_ct = smallest_uniq_substring(lst)\n",
    "print(index_has_min_uniq_ct)\n",
    "[lst[idx] for idx in index_has_min_uniq_ct]\n",
    "# print(index_has_min_uniq_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a473fd4-7c2d-4c9f-957a-2c214a850239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 4, 3, 3, 3, 3, 3, 7]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(set(x)) for x in lst]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ebb288-2f2c-406a-b2cf-bc751a61d67e",
   "metadata": {},
   "source": [
    "# join all these objects together by user_id and convert into df? then try to feature engineer later for ML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4d642a-2788-4baf-a4eb-c100c1529bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all these objects together by user_id and convert into df? then try to feature engineer later for ML\n",
    "\n",
    "# column_info = [\n",
    "#     {\"user_id\": int},\n",
    "#     {\"age\": int},\n",
    "#     {\"gender\": str},\n",
    "#     {\"income\": float},\n",
    "#     {\"credit_score\": int},\n",
    "#     {\"fraud_label\": str}\n",
    "# ]\n",
    "\n",
    "# data = [\n",
    "#     [1, 35, \"Male\", 50000.0, 700, \"Not Fraud\"],\n",
    "#     [2, 45, \"Female\", 60000.0, 720, \"Not Fraud\"],\n",
    "#     [3, 30, \"Male\", 45000.0, 680, \"Fraud\"],\n",
    "#     [4, 50, \"Male\", 70000.0, 750, \"Not Fraud\"],\n",
    "#     [5, 40, \"Female\", 55000.0, 710, \"Fraud\"]\n",
    "# ]\n",
    "\n",
    "# user_labels = [\n",
    "#     [1, \"Not Fraud\"],\n",
    "#     [2, \"Not Fraud\"],\n",
    "#     [3, \"Fraud\"],\n",
    "#     [4, \"Not Fraud\"],\n",
    "#     [5, \"Fraud\"]\n",
    "# ]\n",
    "\n",
    "\n",
    "column_info = [\n",
    "    {\"user_id\": int},\n",
    "    {\"age\": int},\n",
    "    {\"gender\": str},\n",
    "    {\"income\": float},\n",
    "    {\"credit_score\": int},\n",
    "]\n",
    "\n",
    "data = [\n",
    "    [1, 35, \"Male\", 50000.0, 700,],\n",
    "    [2, 45, \"Female\", 60000.0, 720,],\n",
    "    [3, 30, \"Male\", 45000.0, 680, ],\n",
    "    [4, 50, \"Male\", 70000.0, 750, ],\n",
    "    [5, 40, \"Female\", 55000.0, 710,]\n",
    "]\n",
    "\n",
    "user_labels = [\n",
    "    [1, \"Not Fraud\"],\n",
    "    [2, \"Not Fraud\"],\n",
    "    [3, \"Fraud\"],\n",
    "    [4, \"Not Fraud\"],\n",
    "    [5, \"Fraud\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f54699f7-1189-48f7-961d-ed8294663cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': 1, 'age': 35, 'gender': 'Male', 'income': 50000.0, 'credit_score': 700, 'label': 'Not Fraud'}\n",
      "{'user_id': 2, 'age': 45, 'gender': 'Female', 'income': 60000.0, 'credit_score': 720, 'label': 'Not Fraud'}\n",
      "{'user_id': 3, 'age': 30, 'gender': 'Male', 'income': 45000.0, 'credit_score': 680, 'label': 'Fraud'}\n",
      "{'user_id': 4, 'age': 50, 'gender': 'Male', 'income': 70000.0, 'credit_score': 750, 'label': 'Not Fraud'}\n",
      "{'user_id': 5, 'age': 40, 'gender': 'Female', 'income': 55000.0, 'credit_score': 710, 'label': 'Fraud'}\n",
      "[{'user_id': 1, 'age': 35, 'gender': 'Male', 'income': 50000.0, 'credit_score': 700, 'label': 'Not Fraud'}, {'user_id': 2, 'age': 45, 'gender': 'Female', 'income': 60000.0, 'credit_score': 720, 'label': 'Not Fraud'}, {'user_id': 3, 'age': 30, 'gender': 'Male', 'income': 45000.0, 'credit_score': 680, 'label': 'Fraud'}, {'user_id': 4, 'age': 50, 'gender': 'Male', 'income': 70000.0, 'credit_score': 750, 'label': 'Not Fraud'}, {'user_id': 5, 'age': 40, 'gender': 'Female', 'income': 55000.0, 'credit_score': 710, 'label': 'Fraud'}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>Male</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>700</td>\n",
       "      <td>Not Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>Female</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>720</td>\n",
       "      <td>Not Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>680</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>Male</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>750</td>\n",
       "      <td>Not Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>Female</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>710</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age  gender   income  credit_score      label\n",
       "0        1   35    Male  50000.0           700  Not Fraud\n",
       "1        2   45  Female  60000.0           720  Not Fraud\n",
       "2        3   30    Male  45000.0           680      Fraud\n",
       "3        4   50    Male  70000.0           750  Not Fraud\n",
       "4        5   40  Female  55000.0           710      Fraud"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple create_df without data transformation\n",
    "def create_df(column_info, data, user_labels):\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    # i = 5\n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        row = {}\n",
    "        # j = 5\n",
    "        for j in range(len(column_info)):\n",
    "            \n",
    "            col_name =  list(column_info[j].keys())[0]\n",
    "            row[col_name] = data[i][j]\n",
    "            # print(col_name)\n",
    "            # print(data[i][j])\n",
    "            \n",
    "        \n",
    "        row['user_id'] = user_labels[i][0]\n",
    "        row['label'] = user_labels[i][1]       \n",
    "\n",
    "        print(row)\n",
    "        rows.append(row)\n",
    "    \n",
    "    \n",
    "    return(rows)\n",
    "\n",
    "list_dict = create_df(column_info, data, user_labels)\n",
    "\n",
    "\n",
    "# return a list of dictionary; list_dict\n",
    "print(list_dict)\n",
    "df = pd.DataFrame(list_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8cb1e-8251-4b89-aa88-c294d34b2d1e",
   "metadata": {},
   "source": [
    "#  create_df with  data transformation using z-score-norm & one-hot-encoding function ready for logistics regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f197bb8-8c67-4b73-a63f-0f5a4e5fb450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_normalization(data):\n",
    "    mean = sum(data) / len(data)\n",
    "    # print(mean)\n",
    "    stdev = (sum((x-mean) **2 for x in data) /len(data)) **0.5\n",
    "    # print(stdev)\n",
    "    data_norm = [( x-mean) /stdev for x in data]\n",
    "    # print(data_norm)\n",
    "    return(data_norm)\n",
    "\n",
    "\n",
    "def one_hot_encode(data):\n",
    "    unique_values = set(data)\n",
    "    # print('unique_values', unique_values)\n",
    "    encoding = {}\n",
    "    \n",
    "    for i, value in enumerate(unique_values):\n",
    "        # print('i',i)\n",
    "        # print('value',value)\n",
    "\n",
    "        # this is the formula to create binary for every possible uniq class (one-hot encoding)\n",
    "        encoding[value] = [0] *i + [1]+[0]* (len(unique_values) - i - 1)\n",
    "        # print('encoding[value]',encoding[value])\n",
    "    # print('encoding', encoding)\n",
    "    encoded_data = [ encoding[value]  for value in data]\n",
    "    return(encoded_data)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb08fb0-b8ad-4085-9fd5-fe9da1d383a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# j\n",
    " # list of dictionary/json\n",
    "column_info = [\n",
    "    {\"user_id\": int},\n",
    "    {\"age\": int},\n",
    "    {\"gender\": str},\n",
    "    {\"income\": float},\n",
    "    {\"credit_score\": int},\n",
    "]\n",
    "\n",
    "# i \n",
    "# list of list\n",
    "# data = [\n",
    "#     [1, 35, \"Male\", 50000.0, 700,],\n",
    "#     [2, 45, \"Female\", 60000.0, 720,],\n",
    "#     [3, 30, \"Male\", 45000.0, 680, ],\n",
    "#     [4, 50, \"Male\", 70000.0, 750, ],\n",
    "#     [5, 40, \"Female\", 55000.0, 710,]\n",
    "# ]\n",
    "\n",
    "data = [\n",
    "    [1, 35, \"Male\", 50000.0, 700,],\n",
    "    [2, 45, \"Mix\", 60000.0, 720,],\n",
    "    [3, 30, \"Male\", 45000.0, 680, ],\n",
    "    [4, 50, \"Mix\", 70000.0, 750, ],\n",
    "    [5, 40, \"Female\", 55000.0, 710,]\n",
    "]\n",
    "\n",
    "user_labels = [\n",
    "    [1, \"Not Fraud\"],\n",
    "    [2, \"Not Fraud\"],\n",
    "    [3, \"Fraud\"],\n",
    "    [4, \"Not Fraud\"],\n",
    "    [5, \"Fraud\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9aa7b65e-c652-4a23-a9f2-594b048558ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row {'age': -0.7071067811865475, 'gender': [0, 1, 0], 'income': -0.6974858324629157, 'credit_score': -0.5183210553488161, 'user_id': 1, 'label': 0}\n",
      "[-0.7071067811865475, 0, 1, 0, -0.6974858324629157, -0.5183210553488161, 1, 0]\n",
      "****************************************************************************************************\n",
      "row {'age': 0.7071067811865475, 'gender': [1, 0, 0], 'income': 0.46499055497527714, 'credit_score': 0.34554737023254406, 'user_id': 2, 'label': 0}\n",
      "[0.7071067811865475, 1, 0, 0, 0.46499055497527714, 0.34554737023254406, 2, 0]\n",
      "****************************************************************************************************\n",
      "row {'age': -1.414213562373095, 'gender': [0, 1, 0], 'income': -1.278724026182012, 'credit_score': -1.3821894809301762, 'user_id': 3, 'label': 1}\n",
      "[-1.414213562373095, 0, 1, 0, -1.278724026182012, -1.3821894809301762, 3, 1]\n",
      "****************************************************************************************************\n",
      "row {'age': 1.414213562373095, 'gender': [1, 0, 0], 'income': 1.62746694241347, 'credit_score': 1.6413500086045842, 'user_id': 4, 'label': 0}\n",
      "[1.414213562373095, 1, 0, 0, 1.62746694241347, 1.6413500086045842, 4, 0]\n",
      "****************************************************************************************************\n",
      "row {'age': 0.0, 'gender': [0, 0, 1], 'income': -0.11624763874381928, 'credit_score': -0.08638684255813601, 'user_id': 5, 'label': 1}\n",
      "[0.0, 0, 0, 1, -0.11624763874381928, -0.08638684255813601, 5, 1]\n",
      "****************************************************************************************************\n",
      "****************************************************************************************************\n",
      "list of dictionary contain key:val as colname:colvalue\n",
      "\n",
      "[{'age': -0.7071067811865475, 'gender': [0, 1, 0], 'income': -0.6974858324629157, 'credit_score': -0.5183210553488161, 'user_id': 1, 'label': 0}, {'age': 0.7071067811865475, 'gender': [1, 0, 0], 'income': 0.46499055497527714, 'credit_score': 0.34554737023254406, 'user_id': 2, 'label': 0}, {'age': -1.414213562373095, 'gender': [0, 1, 0], 'income': -1.278724026182012, 'credit_score': -1.3821894809301762, 'user_id': 3, 'label': 1}, {'age': 1.414213562373095, 'gender': [1, 0, 0], 'income': 1.62746694241347, 'credit_score': 1.6413500086045842, 'user_id': 4, 'label': 0}, {'age': 0.0, 'gender': [0, 0, 1], 'income': -0.11624763874381928, 'credit_score': -0.08638684255813601, 'user_id': 5, 'label': 1}]\n",
      "****************************************************************************************************\n",
      "nested list contain only values of all featurs for all records\n",
      "\n",
      "[[-0.7071067811865475, 0, 1, 0, -0.6974858324629157, -0.5183210553488161, 1, 0], [0.7071067811865475, 1, 0, 0, 0.46499055497527714, 0.34554737023254406, 2, 0], [-1.414213562373095, 0, 1, 0, -1.278724026182012, -1.3821894809301762, 3, 1], [1.414213562373095, 1, 0, 0, 1.62746694241347, 1.6413500086045842, 4, 0], [0.0, 0, 0, 1, -0.11624763874381928, -0.08638684255813601, 5, 1]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>user_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>-0.697486</td>\n",
       "      <td>-0.518321</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>0.464991</td>\n",
       "      <td>0.345547</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.414214</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "      <td>-1.278724</td>\n",
       "      <td>-1.382189</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.414214</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>1.627467</td>\n",
       "      <td>1.641350</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "      <td>-0.116248</td>\n",
       "      <td>-0.086387</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age     gender    income  credit_score  user_id  label\n",
       "0 -0.707107  [0, 1, 0] -0.697486     -0.518321        1      0\n",
       "1  0.707107  [1, 0, 0]  0.464991      0.345547        2      0\n",
       "2 -1.414214  [0, 1, 0] -1.278724     -1.382189        3      1\n",
       "3  1.414214  [1, 0, 0]  1.627467      1.641350        4      0\n",
       "4  0.000000  [0, 0, 1] -0.116248     -0.086387        5      1"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#  create_df with  data transformation uusing z-score-norm & one-hot-encoding function\n",
    "\n",
    "def create_df_normalized(column_info, data, user_labels):\n",
    "    rows = []\n",
    "    rows_values = []\n",
    "    for i in range(len(data)):\n",
    "        row = {}\n",
    "        # row_values =[]\n",
    "        for j, column_dict in enumerate(column_info):\n",
    "            col_name = list(column_dict.keys())[0]\n",
    "            col_type = list(column_dict.values())[0]\n",
    "            col_data = data[j][i]\n",
    "            # print('col_data',col_data)\n",
    "            # print('col_name',col_name)\n",
    "            # print('col_type',col_type)\n",
    "\n",
    "            if (col_type == int or col_type == float) and col_name != 'user_id':\n",
    "                col_data_norm = z_score_normalization([entry[j] for entry in data])\n",
    "            elif col_type == str:\n",
    "                col_data_norm = one_hot_encode([entry[j] for entry in data])\n",
    "                # print(col_data_norm)\n",
    "            else:\n",
    "                continue\n",
    "           \n",
    "            # print(col_data_norm)\n",
    "            # print('col_data_norm[i]',col_data_norm[i])\n",
    "            row[col_name] = col_data_norm[i]\n",
    "            # print('row[col_name]', row[col_name])\n",
    "        row['user_id'] = user_labels[i][0]\n",
    "        # directly change label from categorical to binary\n",
    "        row['label'] = 1 if user_labels[i][1] == 'Fraud' else 0\n",
    "\n",
    "        # print(row['label'])\n",
    "        print('row', row)\n",
    "        # rows are list of dictionary because it retains both key:value pairs for all featurrs per record\n",
    "        rows.append(row)\n",
    "        flat_list = []\n",
    "        _ = [flat_list.extend(flatten(x)) if isinstance(x, list) else flat_list.append(x) for x in list(row.values())]\n",
    "        print(flat_list)\n",
    "        # rows_values is nested list here because we only need records features values\n",
    "        rows_values.append(flat_list)\n",
    "\n",
    "        print(\"*\" * 100)\n",
    "\n",
    "    return(rows, rows_values)\n",
    "\n",
    "list_dict, list_values = create_df_normalized(column_info, data, user_labels)\n",
    "print(\"*\" * 100)\n",
    "print('list of dictionary contain key:val as colname:colvalue\\n')\n",
    "print(list_dict)\n",
    "print(\"*\" * 100)\n",
    "print('nested list contain only values of all featurs for all records\\n')\n",
    "print(list_values)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(list_dict)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697f4f85-2553-408a-984a-3e6edc656fd1",
   "metadata": {},
   "source": [
    "#  join list of dictionary/json & list of lists & convert to ALL numerical features value when necessary for logistic regression\n",
    "### This means that date / datetime / boolean / string all need to convert differently that can convert into all numerical\n",
    "### output: nested list which list items are numerical values of input features (from original /converted columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8151ae49-37c1-4ab3-87c4-411173edb945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#3 give a list of dictionary /json with type and colname speccification and list of lists for record features values, \n",
    "# also a dictionary for label of the data; make a final output which are list of lists of all nbr presenting featurs capable of having in logistic regression\n",
    "\n",
    "param_schema = [\n",
    "    {\"type\": \"ID\", \"name\": \"user_id\"},\n",
    "    {\"type\": \"Date\", \"name\": \"registration_date\"},\n",
    "    {\"type\": \"DateTime\", \"name\": \"last_login\"},\n",
    "    {\"type\": \"String\", \"name\": \"gender\"},\n",
    "    {\"type\": \"Float\", \"name\": \"income\"},\n",
    "    {\"type\": \"Integer\", \"name\": \"age\"},\n",
    "    {\"type\": \"Boolean\", \"name\": \"is_fraud\"}\n",
    "]\n",
    "\n",
    "training_data = [\n",
    "    [1, \"2022-01-01\", \"2022-01-10 08:30:00\", \"Male\", 50000.0, 35, True],\n",
    "    [2, \"2022-01-02\", \"2022-01-11 09:45:00\", \"Female\", 60000.0, 45, False],\n",
    "    [3, \"2022-01-03\", \"2022-01-12 10:00:00\", \"Male\", 45000.0, 30, True],\n",
    "    [4, \"2022-01-04\", \"2022-01-13 11:15:00\", \"Male\", 70000.0, 50, False],\n",
    "    [5, \"2022-01-05\", \"2022-01-14 12:30:00\", \"Female\", 55000.0, 40, True]\n",
    "]\n",
    "\n",
    "label_data = {\"ID\": True}\n",
    "\n",
    "########################################################################################\n",
    "# output_data = [\n",
    "#     [1, 16436, 16436, 50000.0, 35, 1],\n",
    "#     [2, 16437, 16437, 60000.0, 45, 0],\n",
    "#     [3, 16438, 16438, 45000.0, 30, 1],\n",
    "#     [4, 16439, 16439, 70000.0, 50, 0],\n",
    "#     [5, 16440, 16440, 55000.0, 40, 1]\n",
    "# ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "0c4b2192-0f1a-4ecb-bdfc-863f481c2829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "list_dict\n",
      " [{'user_id': 1, 'registration_date': -1.4142135623730951, 'last_login': -1.4141794863063688, 'gender': [1, 0], 'income': -0.6974858324629157, 'age': -0.7071067811865475, 'is_fraud': 1}, {'user_id': 2, 'registration_date': -0.7071067811865476, 'last_login': -0.6985876620731862, 'gender': [0, 1], 'income': 0.46499055497527714, 'age': 0.7071067811865475, 'is_fraud': 0}, {'user_id': 3, 'registration_date': 0.0, 'last_login': -0.011336108106664279, 'gender': [1, 0], 'income': -1.278724026182012, 'age': -1.414213562373095, 'is_fraud': 1}, {'user_id': 4, 'registration_date': 0.7071067811865476, 'last_login': 0.7042557161265184, 'gender': [1, 0], 'income': 1.62746694241347, 'age': 1.414213562373095, 'is_fraud': 0}, {'user_id': 5, 'registration_date': 1.4142135623730951, 'last_login': 1.419847540359701, 'gender': [0, 1], 'income': -0.11624763874381928, 'age': 0.0, 'is_fraud': 1}]\n",
      "****************************************************************************************************\n",
      "list_values flatten on one-hot feature \n",
      " [[1, -1.4142135623730951, -1.4141794863063688, 1, 0, -0.6974858324629157, -0.7071067811865475, 1], [2, -0.7071067811865476, -0.6985876620731862, 0, 1, 0.46499055497527714, 0.7071067811865475, 0], [3, 0.0, -0.011336108106664279, 1, 0, -1.278724026182012, -1.414213562373095, 1], [4, 0.7071067811865476, 0.7042557161265184, 1, 0, 1.62746694241347, 1.414213562373095, 0], [5, 1.4142135623730951, 1.419847540359701, 0, 1, -0.11624763874381928, 0.0, 1]]\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# ****************************************************************************************************************\n",
    "# \n",
    "# this function convert date/datetime into numerical, categorical into binary /on-hot encoding, \n",
    "# the function allow capability of z-sore normalized for the right numerical \n",
    "# keep user_id as original in the first position of each nested list, convert categorical label into binary\n",
    "# def create_df_all_numerical(param_schema, training_data, label_data):\n",
    "#\n",
    "# ****************************************************************************************************************\n",
    "def create_df_all_numerical_norm(param_schema, training_data, label_data):\n",
    "    rows = []\n",
    "    \n",
    "    rows_values = []\n",
    "    # i  up to 5\n",
    "    for i in range(len(training_data)):\n",
    "        \n",
    "        row = {}\n",
    "        \n",
    "        # j up to 7\n",
    "        for j, columnn_dict in enumerate(param_schema):\n",
    "\n",
    "            col_type = list(columnn_dict.values())[0]\n",
    "            col_name = list(columnn_dict.values())[1]\n",
    "            \n",
    "            # this allow to get one column at a time from training_data\n",
    "            col_data = [entry[j] for entry in training_data]\n",
    "\n",
    "            # the three if-else are mutually exclusive so need to treat it as a group of if-else conditions tgt\n",
    "            if col_type == 'Date':\n",
    "                # col_data = dt.datetime.strptime(col_data, '%Y-%m-%d').timestamp() *****\n",
    "                col_data= [dt.datetime.strptime(x, '%Y-%m-%d').timestamp() for x in col_data]\n",
    "                # z-score normalized numerical Date if needed\n",
    "                col_data = z_score_normalization(col_data)\n",
    "\n",
    "            elif col_type == 'DateTime':\n",
    "                col_data = [dt.datetime.strptime(x, '%Y-%m-%d %H:%M:%S').timestamp() for x in col_data]\n",
    "                # z-score normalized numerical DateTime if needed *****\n",
    "                col_data = z_score_normalization(col_data)\n",
    "\n",
    "                # print('col_data',col_data)\n",
    "            # z-score normalized numerical if needed  *****\n",
    "            elif (col_type == 'Integer' or col_type == 'Float'):\n",
    "                col_data = z_score_normalization(col_data)\n",
    "                # print(col_data)\n",
    "\n",
    "#                 # print('col_data',col_data)\n",
    "\n",
    "            elif col_type == \"Boolean\":\n",
    "                col_data = [1 if x == True else 0  for x in col_data]\n",
    "\n",
    "            elif col_type == 'String':\n",
    "                col_data = one_hot_encode(col_data)\n",
    "            row[col_name] = col_data[i]\n",
    "\n",
    "        # this block try to only obtain all value from all key and output individually\n",
    "        row_values = list(row.values())    \n",
    "        flat_list = []   \n",
    "        # underscore \"-\" is used as placeholder when you need to perform operation on each element without actually ref to the element itself\n",
    "        # usually list comprehension is for create list, not for extend() or append() which is done here.\n",
    "        _ = [ flat_list.extend(flatten(x)) if isinstance(x,list) else flat_list.append(x) for x in row_values]\n",
    "\n",
    "        # rows contains items of dictionary which key:value are colname:colvalue pair              \n",
    "        rows.append(row)\n",
    "        rows_values.append(flat_list)\n",
    "        # rows_values.append(row_values)   #just use row_values if want the unflatten version of all values in nested list\n",
    "\n",
    "    print('*' *100)\n",
    "    return(rows, rows_values)\n",
    "\n",
    "list_dict , list_values = create_df_all_numerical_norm(param_schema, training_data, label_data)\n",
    "\n",
    "print('list_dict\\n',list_dict)\n",
    "print('*' *100)\n",
    "print('list_values flatten on one-hot feature \\n', list_values)\n",
    "print('*' *100)\n",
    "\n",
    "# df = pd.DataFrame(list_dict)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c98dc-fffb-4cc4-89a3-cf971cf2b7af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "59893262-a19d-4978-a864-512fbfed82eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "list_dict\n",
      " [{'user_id': 1, 'registration_date': -1.4142135623730951, 'last_login': -1.4141794863063688, 'gender': [1, 0], 'income': -0.6974858324629157, 'age': -0.7071067811865475, 'is_fraud': 1}, {'user_id': 2, 'registration_date': -0.7071067811865476, 'last_login': -0.6985876620731862, 'gender': [0, 1], 'income': 0.46499055497527714, 'age': 0.7071067811865475, 'is_fraud': 0}, {'user_id': 3, 'registration_date': 0.0, 'last_login': -0.011336108106664279, 'gender': [1, 0], 'income': -1.278724026182012, 'age': -1.414213562373095, 'is_fraud': 1}, {'user_id': 4, 'registration_date': 0.7071067811865476, 'last_login': 0.7042557161265184, 'gender': [1, 0], 'income': 1.62746694241347, 'age': 1.414213562373095, 'is_fraud': 0}, {'user_id': 5, 'registration_date': 1.4142135623730951, 'last_login': 1.419847540359701, 'gender': [0, 1], 'income': -0.11624763874381928, 'age': 0.0, 'is_fraud': 1}]\n",
      "****************************************************************************************************\n",
      "list_values flatten on one-hot feature \n",
      " [[1, -1.4142135623730951, -1.4141794863063688, 1, 0, -0.6974858324629157, -0.7071067811865475, 1], [2, -0.7071067811865476, -0.6985876620731862, 0, 1, 0.46499055497527714, 0.7071067811865475, 0], [3, 0.0, -0.011336108106664279, 1, 0, -1.278724026182012, -1.414213562373095, 1], [4, 0.7071067811865476, 0.7042557161265184, 1, 0, 1.62746694241347, 1.414213562373095, 0], [5, 1.4142135623730951, 1.419847540359701, 0, 1, -0.11624763874381928, 0.0, 1]]\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# sample input data\n",
    "param_schema = [\n",
    "    {\"type\": \"ID\", \"name\": \"user_id\"},\n",
    "    {\"type\": \"Date\", \"name\": \"registration_date\"},\n",
    "    {\"type\": \"DateTime\", \"name\": \"last_login\"},\n",
    "    {\"type\": \"String\", \"name\": \"gender\"},\n",
    "    {\"type\": \"Float\", \"name\": \"income\"},\n",
    "    {\"type\": \"Integer\", \"name\": \"age\"},\n",
    "    {\"type\": \"Boolean\", \"name\": \"is_fraud\"}\n",
    "]\n",
    "\n",
    "training_data = [\n",
    "    [1, \"2022-01-01\", \"2022-01-10 08:30:00\", \"Male\", 50000.0, 35, True],\n",
    "    [2, \"2022-01-02\", \"2022-01-11 09:45:00\", \"Female\", 60000.0, 45, False],\n",
    "    [3, \"2022-01-03\", \"2022-01-12 10:00:00\", \"Male\", 45000.0, 30, True],\n",
    "    [4, \"2022-01-04\", \"2022-01-13 11:15:00\", \"Male\", 70000.0, 50, False],\n",
    "    [5, \"2022-01-05\", \"2022-01-14 12:30:00\", \"Female\", 55000.0, 40, True]\n",
    "]\n",
    "\n",
    "label_data = {\"ID\": True}\n",
    "\n",
    "\n",
    "# sample output data\n",
    "# ****************************************************************************************************\n",
    "# list_dict\n",
    "#  [{'user_id': 1, 'registration_date': -1.4142135623730951, 'last_login': -1.4141794863063688, 'gender': [1, 0], 'income': -0.6974858324629157, 'age': -0.7071067811865475, 'is_fraud': 1}, {'user_id': 2, 'registration_date': -0.7071067811865476, 'last_login': -0.6985876620731862, 'gender': [0, 1], 'income': 0.46499055497527714, 'age': 0.7071067811865475, 'is_fraud': 0}, {'user_id': 3, 'registration_date': 0.0, 'last_login': -0.011336108106664279, 'gender': [1, 0], 'income': -1.278724026182012, 'age': -1.414213562373095, 'is_fraud': 1}, {'user_id': 4, 'registration_date': 0.7071067811865476, 'last_login': 0.7042557161265184, 'gender': [1, 0], 'income': 1.62746694241347, 'age': 1.414213562373095, 'is_fraud': 0}, {'user_id': 5, 'registration_date': 1.4142135623730951, 'last_login': 1.419847540359701, 'gender': [0, 1], 'income': -0.11624763874381928, 'age': 0.0, 'is_fraud': 1}]\n",
    "# ****************************************************************************************************\n",
    "# list_values flatten on one-hot feature \n",
    "#  [[1, -1.4142135623730951, -1.4141794863063688, 1, 0, -0.6974858324629157, -0.7071067811865475, 1], [2, -0.7071067811865476, -0.6985876620731862, 0, 1, 0.46499055497527714, 0.7071067811865475, 0], [3, 0.0, -0.011336108106664279, 1, 0, -1.278724026182012, -1.414213562373095, 1], [4, 0.7071067811865476, 0.7042557161265184, 1, 0, 1.62746694241347, 1.414213562373095, 0], [5, 1.4142135623730951, 1.419847540359701, 0, 1, -0.11624763874381928, 0.0, 1]]\n",
    "# ****************************************************************************************************\n",
    "\n",
    "\n",
    "def z_score_normalization(data):\n",
    "    mean = sum(data) / len(data)\n",
    "    stdev = (sum((x-mean) **2 for x in data) /len(data)) **0.5\n",
    "    data_norm = [( x-mean) /stdev for x in data]\n",
    "    return(data_norm)\n",
    "\n",
    "\n",
    "def one_hot_encode(data):\n",
    "    # understand how many possible unique class levels\n",
    "    unique_values = set(data)\n",
    "    encoding = {}\n",
    "    for i, value in enumerate(unique_values):\n",
    "        # this is the formula to create binary for every possible uniq class (one-hot encoding)\n",
    "        encoding[value] = [0] *i + [1]+[0]* (len(unique_values) - i - 1)\n",
    "    # for every item in the data list, convert each into respective binary encoding based on encoding dict just createdd\n",
    "    encoded_data = [ encoding[value]  for value in data]\n",
    "    return(encoded_data)\n",
    "           \n",
    "def flatten(lst):\n",
    "    flat_list = []\n",
    "    for item in lst:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(flatten(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list  \n",
    "\n",
    "import datetime as dt\n",
    "# ****************************************************************************************************************\n",
    "# \n",
    "# this function convert date/datetime into numerical, categorical into binary /on-hot encoding, \n",
    "# the function allow capability of z-sore normalized for the right numerical \n",
    "# keep user_id as original in the first position of each nested list, convert categorical label into binary\n",
    "# def create_df_all_numerical(param_schema, training_data, label_data):\n",
    "#\n",
    "# ****************************************************************************************************************\n",
    "def data_preprocess_binary_classification(param_schema, training_data, label_data):\n",
    "    rows = []\n",
    "    \n",
    "    rows_values = []\n",
    "    # i  up to 5\n",
    "    for i in range(len(training_data)):\n",
    "        \n",
    "        row = {}\n",
    "        \n",
    "        # j up to 7\n",
    "        for j, columnn_dict in enumerate(param_schema):\n",
    "\n",
    "            col_type = list(columnn_dict.values())[0]\n",
    "            col_name = list(columnn_dict.values())[1]\n",
    "            \n",
    "            # this allow to get one column at a time from training_data\n",
    "            col_data = [entry[j] for entry in training_data]\n",
    "\n",
    "            # the three if-else are mutually exclusive so need to treat it as a group of if-else conditions tgt\n",
    "            if col_type == 'Date':\n",
    "                # col_data = dt.datetime.strptime(col_data, '%Y-%m-%d').timestamp() *****\n",
    "                col_data= [dt.datetime.strptime(x, '%Y-%m-%d').timestamp() for x in col_data]\n",
    "                # z-score normalized numerical Date if needed\n",
    "                col_data = z_score_normalization(col_data)\n",
    "\n",
    "            elif col_type == 'DateTime':\n",
    "                col_data = [dt.datetime.strptime(x, '%Y-%m-%d %H:%M:%S').timestamp() for x in col_data]\n",
    "                # z-score normalized numerical DateTime if needed *****\n",
    "                col_data = z_score_normalization(col_data)\n",
    "\n",
    "                # print('col_data',col_data)\n",
    "            # z-score normalized numerical if needed  *****\n",
    "            elif (col_type == 'Integer' or col_type == 'Float'):\n",
    "                col_data = z_score_normalization(col_data)\n",
    "                # print(col_data)\n",
    "\n",
    "#                 # print('col_data',col_data)\n",
    "\n",
    "            elif col_type == \"Boolean\":\n",
    "                col_data = [1 if x == True else 0  for x in col_data]\n",
    "\n",
    "            elif col_type == 'String':\n",
    "                col_data = one_hot_encode(col_data)\n",
    "            row[col_name] = col_data[i]\n",
    "\n",
    "        # this block try to only obtain all value from all key and output individually\n",
    "        row_values = list(row.values())    \n",
    "        flat_list = []   \n",
    "        # underscore \"-\" is used as placeholder when you need to perform operation on each element without actually ref to the element itself\n",
    "        # usually list comprehension is for create list, not for extend() or append() which is done here.\n",
    "        _ = [ flat_list.extend(flatten(x)) if isinstance(x,list) else flat_list.append(x) for x in row_values]\n",
    "\n",
    "        # rows contains items of dictionary which key:value are colname:colvalue pair              \n",
    "        rows.append(row)\n",
    "        rows_values.append(flat_list)\n",
    "        # rows_values.append(row_values)   #just use row_values if want the unflatten version of all values in nested list\n",
    "\n",
    "    print('*' *100)\n",
    "    return(rows, rows_values)\n",
    "\n",
    "list_dict , list_values = data_preprocess_binary_classification(param_schema, training_data, label_data)\n",
    "\n",
    "print('list_dict\\n',list_dict)\n",
    "print('*' *100)\n",
    "print('list_values flatten on one-hot feature \\n', list_values)\n",
    "print('*' *100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d19c7-6163-4512-a5db-d26cc0ece72c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0850f6b4-a440-479c-9790-ed3f93b09c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "551de6c7-1899-45d3-a9f4-9f94dc5749a0",
   "metadata": {},
   "source": [
    "# Possible Sift Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "0d17310e-b912-4945-8daa-6ffa2818d4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 2 2 2\n",
      "1 0\n",
      "precision, recell and f1 scores are: 0.6666666666666666 0.6666666666666666 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# actual interview problem: given a list vectors, the actual label vs. the pred label, try to figure out the\n",
    "# precision, recall and f1 score for model evaluation metrics iin binary classification\n",
    "\n",
    "actual_label = [1, 0, 1, 0, 1, 0, 1, 0, 1, 1]\n",
    "pred_label =   [1, 0, 1, 0, 1, 1, 0, 1, 1, 0]\n",
    "# pred_label = [1, 0, 1, 0, 1, 1, 0, 1, 1]\n",
    "\n",
    "def eval_model_binary_classification(actual_label, pred_label ):\n",
    "    \n",
    "    if len(actual_label) != len(pred_label):\n",
    "        print('Two input label vectors are of different length! Exit function and please validate data!')\n",
    "        return(None, None, None)\n",
    "    \n",
    "    else:\n",
    "        tp = fp = tn = fn = 0\n",
    "        for actual, pred in zip(actual_label, pred_label):\n",
    "            if actual == 1 and actual == pred:\n",
    "                tp += 1\n",
    "            elif actual == 1 and actual != pred:\n",
    "                fn += 1\n",
    "            elif actual == 0 and  actual == pred:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        \n",
    "        print(tp, fp, tn, fn)\n",
    "        precision = tp / (tp + fp)\n",
    "        recall = tp / (tp + fn)\n",
    "        f1 = (2 *  precision * recall) / (precision + recall)\n",
    "        \n",
    "        print(actual, pred)\n",
    "        \n",
    "        \n",
    "        return( precision, recall, f1)\n",
    "\n",
    "\n",
    "precision, recall, f1 = eval_model_binary_classification(actual_label, pred_label)\n",
    "\n",
    "print('precision, recell and f1 scores are:', precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb3744-01e2-4b5a-a086-fd606004fa3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cfc28-66a0-47eb-9392-41b2f0547c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc8a7f7-80f7-4dd0-9ee6-38ec67db4b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7fd5f-5287-4b1f-9325-4f3748cdd31f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "056708f3-294c-4fcc-a55e-433d6af1d118",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFS for weakly connected components, not excplicit on DISTINCT weakly connected components during traversal\n",
      "[[1, 2, 3, 4, 5]]\n",
      "DFS for weakly connected components, not excplicit on DISTINCT weakly connected components during traversal\n",
      "[[1, 3, 4, 5, 2]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fraudulent user detection, find weakly connected component in large graph\n",
    "# (100k nodes, single machine). This question needs to be compiled and run on\n",
    "# a mac.\n",
    "# clarification on the expected definition of weakly connected components *****\n",
    "\n",
    "# sample input: adjacency list of graph\n",
    "graph = {\n",
    "    1: [2, 3],\n",
    "    2: [1, 3],\n",
    "    3: [1, 2, 4],\n",
    "    4: [3, 5],\n",
    "    5: [4]\n",
    "}\n",
    "\n",
    "# sample output\n",
    "[[1, 2, 3], [4, 5]]\n",
    "\n",
    "# Breadth-First Search (BFS):\n",
    "# Depth-First Search (DFS):\n",
    "# use BFS or DFS to find weakly connected nodes group and have them together in every list item in a nested list:\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "def bfs(graph, start):\n",
    "    visited = set()\n",
    "    queue = deque([start])\n",
    "    component = []\n",
    "    \n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        if node not in visited:\n",
    "            visited.add(node)\n",
    "            component.append(node)\n",
    "            queue.extend(graph[node])\n",
    "    return(component)\n",
    "\n",
    "\n",
    "def find_weakly_connected_components(graph):\n",
    "    visited = set()\n",
    "    components = []\n",
    "    \n",
    "    for node in graph:\n",
    "        if node not in visited:\n",
    "            component = bfs(graph, node)\n",
    "            components.append(component)\n",
    "            visited.update(component)\n",
    "            \n",
    "    return(components)\n",
    "\n",
    "\n",
    "weakly_connected_components = find_weakly_connected_components(graph)\n",
    "print('BFS for weakly connected components, not excplicit on DISTINCT weakly connected components during traversal')\n",
    "print(weakly_connected_components)\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "def dfs(graph, node, visited):\n",
    "    component = []\n",
    "    stack = [node]\n",
    "    \n",
    "    while stack:\n",
    "        current_node = stack.pop()\n",
    "        if current_node not in visited:\n",
    "            visited.add(current_node)\n",
    "            component.append(current_node)\n",
    "            stack.extend([neighbor for neighbor in graph[current_node] if neighbor not in visited])\n",
    "    return(component)\n",
    "\n",
    "def find_weakly_connected_components(graph):\n",
    "    visited = set()\n",
    "    components = []\n",
    "    \n",
    "    for node in graph: \n",
    "        if node not in visited:\n",
    "            component = dfs(graph, node, visited)\n",
    "            components.append(component)\n",
    "    return(components)\n",
    "\n",
    "weakly_connected_components = find_weakly_connected_components(graph)\n",
    "print('DFS for weakly connected components, not excplicit on DISTINCT weakly connected components during traversal')\n",
    "print(weakly_connected_components)\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "\n",
    "# modify the traversal algorithms to handle the identification of separate weakly connected components explicitly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "393e6874-a050-4476-bcef-b7ece27164a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Node object at 0x7fe764eef550>\n",
      "<__main__.Node object at 0x7fe764eef550>\n"
     ]
    }
   ],
   "source": [
    "# given a graph and a node in the graph, return a deep copy of the node\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, val=None):\n",
    "        self.val = val\n",
    "        self.neighbors = []\n",
    "\n",
    "# Create nodes\n",
    "node1 = Node(1)\n",
    "node2 = Node(2)\n",
    "node3 = Node(3)\n",
    "node4 = Node(4)\n",
    "\n",
    "# Create edges\n",
    "node1.neighbors.append(node2)\n",
    "node1.neighbors.append(node4)\n",
    "node2.neighbors.append(node1)\n",
    "node2.neighbors.append(node3)\n",
    "node3.neighbors.append(node2)\n",
    "node3.neighbors.append(node4)\n",
    "node4.neighbors.append(node1)\n",
    "node4.neighbors.append(node3)\n",
    "\n",
    "# Define the input node\n",
    "input_node = node1\n",
    "\n",
    "print(node1)\n",
    "print(input_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "a6532e11-fb2c-4ced-bf11-e479f1060c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'pear': 856, 'banana': 570, 'apple': 400, 'orange': 174})\n",
      "{'pear': 0.428, 'apple': 0.2, 'orange': 0.087, 'banana': 0.285}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# given an array of fruits, and another array of weights of fruits, write a function to pick the fruits \n",
    "# randomly with a probabilityy distribution equal to its weights\n",
    "\n",
    "# random distributions:\n",
    "# lognormal\n",
    "# negative exponential\n",
    "# gamma\n",
    "# beta\n",
    "# random.randint()\n",
    "\n",
    "# Generate random numbers from a normal distribution\n",
    "# np.random.normal(loc=0, scale=1, size=10)\n",
    "# # Generate random numbers from a uniform distribution\n",
    "# np.random.uniform(low=0, high=1, size=10)\n",
    "# # Generate random numbers from a binomial distribution\n",
    "# np.random.binomial(n=10, p=0.5, size=10)\n",
    "# # Generate random numbers from a Poisson distribution\n",
    "# np.random.poisson(lam=3, size=10)\n",
    "# # Generate random numbers from an exponential distribution\n",
    "# np.random.exponential(scale=1, size=10)\n",
    "\n",
    "##############################################################################\n",
    "# random.random()  any float b/w [0,1)\n",
    "# random.randint(a, b) random integer b/w [a, b]\n",
    "# random.uniform(a, b) random float b/w [a,b]\n",
    "\n",
    "# shuffle(lst) shuffle the lst\n",
    "# choice(lst)  random pick single item from lst\n",
    "##############################################################################\n",
    "# logics explain: bascially cumulative_weight acts as a CDF, which correlate AUC of the CDF for each fruits in ascending order of the fruit list, \n",
    "# the cumulative_weight value acts as the upper bound threshold respective to each fruit,lower bound of the AUC for that fruit will be the previous cumulative_weight \n",
    "# of last position fruits, so bascially to test if the rand_num is <= to any particular cumulative_weight value then output the respective fruit is to \n",
    "# indicate /pick the fruit based on the AUC/shade that belong to that fruit,  fruit contains bigger weight would yield higher AUC shade \n",
    "# of that fruit, so gives the bigger bandwidth for the rand_num to fall in\n",
    "# the fruit with higher weight have higher chance of being chosen\n",
    "\n",
    "fruits = [\"apple\", \"banana\", \"orange\", \"pear\"]\n",
    "fruits_weight = [2,3,1,4]\n",
    "\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "def pick_fruits(fruits, weights):\n",
    "    \n",
    "    total_weight = sum(weights)\n",
    "    # print('total_weight',total_weight)\n",
    "    # use uniform distribution b/w a,b in float, use float b/c prob is suppose to be PDF but not PMF here\n",
    "    # b/c weights are all int so the cdf should construct in way that range b/w 0 and the sum of all weights\n",
    "    rand_num = random.uniform(0,  total_weight)\n",
    "    cumulative_weight = 0\n",
    "    \n",
    "    # print('rand_num',rand_num)\n",
    "    \n",
    "    for fruit, weight in zip(fruits, weights):\n",
    "        # print(fruit, weight  )\n",
    "        cumulative_weight += weight\n",
    "        # print(cumulative_weight)\n",
    "        \n",
    "        if rand_num <= cumulative_weight:\n",
    "            # print('OUT',fruit)\n",
    "            return( fruit)\n",
    "######################### SIMULATION ###########################################\n",
    "# simulation to randomly generate a random fruit from the fruits X times based on the w/ prob dist on its weights\n",
    "fruit_list = []\n",
    "for i in range(2000):\n",
    "    output = pick_fruits(fruits, fruits_weight)\n",
    "    fruit_list.append(output)\n",
    "     \n",
    "\n",
    "# easy way to use the random.choices() func. instead\n",
    "# fruit_list = random.choices(fruits, fruits_weight, k = 1000)\n",
    "############################ VALIDATION #########################################################\n",
    "# this is to check & confirm if the simulation is done right basd on the prob distribution using respective fruit weight\n",
    "dist = Counter(fruit_list)\n",
    "print(dist)\n",
    "total = sum(dist.values())\n",
    "fruit_prob = {}\n",
    "for key, val in dist.items():\n",
    "    prob = val/total\n",
    "    fruit_prob[key] = prob\n",
    "\n",
    "print(fruit_prob)\n",
    "# fruits = [\"apple\", \"banana\", \"orange\", \"pear\"]\n",
    "# fruits_weight = [2,3,1,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "e9c42e01-9e11-41f0-ac5a-b38bb0d45621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single random object generator:\n",
      " C\n",
      "Counter({'B': 5008, 'A': 3044, 'C': 1948})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'B': 0.5008, 'C': 0.1948, 'A': 0.3044}"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given a frequency distribution of objects, write a random object generator which produces objects based on their probability distribution\n",
    "\n",
    "# in this prompt, the data structure of this sample input is different compare to last one\n",
    "# because this obj already contain the associated prob for each items in the obj, so the obj in dictionary datatype might be more appropriate\n",
    "# so the key:val pairs would you the paired info of individual obj and its respective prob. \n",
    "\n",
    "# sample input (population mean, prob distribution)\n",
    "object_freq = {\"A\": 0.3, \"B\": 0.5, \"C\": 0.2}\n",
    "\n",
    "import random \n",
    "from collections import Counter\n",
    "\n",
    "def random_generator_by_obj_freq(object_freq):\n",
    "    \n",
    "    rand_num = random.random()\n",
    "    # print(rand_num)\n",
    "    # print(object_freq)\n",
    "    cumulative_prob = 0\n",
    "    \n",
    "    for obj, prob in object_freq.items():\n",
    "        \n",
    "        cumulative_prob += prob\n",
    "        # print(obj, obj)\n",
    "        # print(cumulative_prob)\n",
    "        if rand_num <= cumulative_prob:\n",
    "            return(obj)\n",
    "\n",
    "# when test the function and generate 1 value/obj at a time\n",
    "obj = random_generator_by_obj_freq(object_freq)\n",
    "print('single random object generator:\\n', obj)\n",
    "\n",
    "# as n --> large value,( nbr trials increase), the freq. of obj generation (sample mean) will converge to population mean\n",
    "# as sample size increases, tthe observed freq. of an event will tend to approach to its true prob.\n",
    "# why: b/c as sample size goes up, tthe effect of the randomness in the sampling process become less significant, the relative freq. of the obj.\n",
    "# will more closely reflect their underlying prob.\n",
    "\n",
    "\n",
    "# LLN focuses on the behavior of individual frequencies or proportions as the sample size increases, aiming to approximate the true probability distribution.\n",
    "# CLT focuses on the distribution of sample means (or other sample statistics) as the sample size increases, predicting that they will approach a normal distribution.\n",
    "\n",
    "\n",
    "# CLT - the distribution of sample mean of many sampling (MEAN OF MEANS) should approximate to Normal\n",
    "# (Law of Large Number): relevant to generating random obj based on their prob. distribution\n",
    "random_generate_obj_list = []\n",
    "for i in range(10000):\n",
    "    obj = random_generator_by_obj_freq(object_freq)\n",
    "    random_generate_obj_list.append(obj)\n",
    "\n",
    "# print(random_generate_obj_list)\n",
    "# print(len( random_generate_obj_list))\n",
    "obj_dist = Counter(random_generate_obj_list)\n",
    "print(obj_dist)\n",
    "\n",
    "total_cnt = sum(obj_dist.values())\n",
    "validation = {}\n",
    "\n",
    "for key, val in obj_dist.items():\n",
    "    \n",
    "    prob = val/ total_cnt\n",
    "    validation[key] =prob\n",
    "\n",
    "# validate if your func simulate random obj by obj prob. as expect\n",
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "04825568-949f-4018-a420-cf877571ec73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Given 1 billion data point (key, value with 15 bytes of string and 8 byte\n",
    "# of double value); store this in the memory that supports fast lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "5392bbe3-b21c-4bd7-be0a-30b0f49e8ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1/1\n",
      "1\n",
      "+\n",
      "1\n",
      "/\n",
      "1\n",
      "1 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate an arithmetic expression that only involves multiplication and addition.\n",
    "\n",
    "# sample input\n",
    "expression = \"3 + 4 * 2 * 5 + 6\"\n",
    "\n",
    "expression = \"3 + 4 * 2 * 5  - 6\"\n",
    "expression = \"1+1/1\"\n",
    "\n",
    "re.search(r\"\\*\", expression)\n",
    "\n",
    "import re\n",
    "\n",
    "def evaluate_arithmetic(expression):\n",
    "    \n",
    "    expression = expression.replace(\" \", \"\")\n",
    "    \n",
    "    print(expression)\n",
    "    found = False \n",
    "    found_desired = 0\n",
    "    found_undesired = 0\n",
    "    for i in expression:\n",
    "        print(i)\n",
    "        if i in ['*','+']:\n",
    "            found_desired += 1\n",
    "\n",
    "        elif i in ['-', '/']:\n",
    "            found_undesired += 1\n",
    "    \n",
    "    if found_desired > 0 and found_undesired == 0:\n",
    "        found = True\n",
    "    else:\n",
    "        found = False\n",
    "    \n",
    "    print(found_desired,found_undesired)\n",
    "    return(found)\n",
    "\n",
    "evaluate_arithmetic(expression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "9121fb16-53e6-418e-a952-348d8266e498",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(1, 2), match='+'>\n"
     ]
    }
   ],
   "source": [
    "expression = \"3 + 4 * 2 * 5 + 6\"\n",
    "\n",
    "expression = \"3 + 4 * 2 * 5  - 6\"\n",
    "expression = \"1+1*1\"\n",
    "\n",
    "pattern = r\"[\\+\\*]\"\n",
    "\n",
    "match = re.search(pattern, expression)\n",
    "print(match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb00b90-08fa-4c2f-b4de-0d5f4dc1c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TwoSum problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "f235c5a0-1411-42f2-969f-7963eac7474b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "b1147e6b-f665-4ec5-919f-083a5e297d01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P\n",
      "Y\n",
      "H\n",
      "O\n",
      "N\n",
      "input_string:\n",
      "PYTHON\n",
      "element_existed_q:\n",
      "True\n",
      "elements_found_list:\n",
      "['P', 'Y', 'H', 'O', 'N']\n"
     ]
    }
   ],
   "source": [
    "# given a string, or a list of string items, see if they can be seperated to identify the Chemical elements eg. Na, Cl, Fe, Li\n",
    "# also given a list of all chemical elements string items\n",
    "# - recursive\n",
    "# dp?\n",
    "\n",
    "\n",
    "elements = [\"H\", \"He\", \"Li\", \"Be\", \"B\", \"C\", \"N\", \"O\", \"F\", \"Ne\",\"Na\", \"Mg\", \"Al\", \"Si\", \"P\", \"S\", \"Cl\", \"Ar\",\n",
    "            \"K\", \"Ca\", \"Sc\", \"Ti\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\", \"Ga\", \"Ge\", \"As\", \"Se\", \"Br\", \"Kr\",\n",
    "            \"Rb\", \"Sr\", \"Y\", \"Zr\", \"Nb\", \"Mo\", \"Tc\", \"Ru\", \"Rh\", \"Pd\", \"Ag\", \"Cd\", \"In\", \"Sn\", \"Sb\", \"Te\", \"I\", \"Xe\",\n",
    "            \"Cs\", \"Ba\", \"Hf\", \"Ta\", \"W\", \"Re\", \"Os\", \"Ir\", \"Pt\", \"Au\", \"Hg\", \"Tl\", \"Pb\", \"Bi\", \"Po\", \"At\", \"Rn\",\n",
    "            \"Fr\", \"Ra\", \"Rf\", \"Db\", \"Sg\", \"Bh\", \"Hs\", \"Mt\", \"Ds\", \"Rg\", \"Cn\", \"Nh\", \"Fl\", \"Mc\", \"Lv\", \"Ts\", \"Og\"]\n",
    "\n",
    "# make elements lower case\n",
    "elements_lower = [x.lower() for x in elements]\n",
    "# Given a string, check if it could be decomposed into substring, which is\n",
    "# each an element symbol. physics => P H Y Si C S\n",
    "# Prompt: Given a string, check if it can be decomposed into substrings, each representing an element symbol.\n",
    "\n",
    "# All match samples\n",
    "input_string = \"PHYSICS\"\n",
    "input_string = \"PYTHON\"\n",
    "\n",
    "# partial match samples\n",
    "# input_string = \"XYLOPHONE\"\n",
    "# input_string = \"ELEPHANT\"\n",
    "# input_string = \"number\"\n",
    "# input_string = \"GIRAFFE\"\n",
    "# input_string = \"LANGUAGE\"\n",
    "# input_string = \"HELLO\"\n",
    "# input_string = \"WORLD\"\n",
    "# input_string = \"CHEMISTRY\"\n",
    "\n",
    "# \n",
    "# # None match samples\n",
    "# input_string = \"ZERO\"\n",
    "# input_string = \"JAVA\"\n",
    "\n",
    "# input_string = \"\"\n",
    "# input_string = \"\"\n",
    "\n",
    "# case-insentitive: now make the element list to be all lower cases, just match for case insensitive string match\n",
    "def check_chemical_elements(elements, input_string):\n",
    "    \n",
    "    elements_found_list = []\n",
    "    \n",
    "    n = len(input_string)\n",
    "    # print('n',n)\n",
    "    for i in range(n):\n",
    "        # print('i', i)\n",
    "        for j in range(i+1, n+1):\n",
    "            # print('j',j)\n",
    "            substring = input_string[i:j]\n",
    "            # print(substring)\n",
    "            # depend on prompt is asking to match for case-sensitive/insensitive\n",
    "            if substring.lower() in elements_lower:\n",
    "            # if substring in elements:\n",
    "\n",
    "                print(substring)\n",
    "                elements_found_list.append(substring)\n",
    "                continue\n",
    "    \n",
    "    if len(elements_found_list) > 1:\n",
    "        found = True\n",
    "    else:\n",
    "        found = False\n",
    "        elements_found_list = None\n",
    "        print(\"*\" *100)\n",
    "        \n",
    "    # return set() or list() depend on if duplicates matters\n",
    "    # return(found, set(elements_found_list))\n",
    "    return(found, elements_found_list)\n",
    "\n",
    "element_existed_q, elements_found_list = check_chemical_elements(elements, input_string)\n",
    "print('input_string:')\n",
    "print(input_string)\n",
    "\n",
    "print('element_existed_q:')\n",
    "print(element_existed_q)\n",
    "\n",
    "print('elements_found_list:')\n",
    "print(elements_found_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b7b10-adae-4bc1-beb8-d45eaf3f94e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bdc7047-8e05-4b69-9d28-4bda13512d39",
   "metadata": {},
   "source": [
    "# study when additional time available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab32c0a9-121e-4dde-b673-845c2c477050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LESS POSSIBLEE\n",
    "\n",
    "# do wordbreak\n",
    "# one way is to use \"dp\" to do it\n",
    "# another less ideal way is \"backtracking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cffc67-6128-40ab-970b-1b753bab6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LESS POSSIBLEE\n",
    "\n",
    "# Given a binary search tree, find least common ancestor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "cef53344-1c19-45af-8928-111115e71c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# level order transversal of a tree, \n",
    "# then make different between a shallow vs. deep copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf8fb2-d3a8-4609-a710-eae84b4c63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LESS POSSIBLEE\n",
    "\n",
    "#  Given a binary tree with parent pointers (pointers that direct from leaves to the root), design an\n",
    "# O(1) space complexity algorithm to find the lowest common ancestor of any two nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ed426b4a-70ad-4c60-a82d-9fc24e68bb6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# how to optimized an sorted array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "356ff67c-0815-493f-9621-b4ce298a0cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeetCode original:\n",
    "# LESS POSSIBLEE\n",
    "# PopulationNext right pointers in each node II\n",
    "# - Queue BFS\n",
    "# - dual pointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "8e0621ea-bae7-4415-aee0-f14b6f1fc07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LESS POSSIBLEE\n",
    "\n",
    "# 1 given a nxn chessboard, there are only pawns (white and black) on it. Say\n",
    "# one side is the start and its opposite side is the end. There is one white\n",
    "# pawn on the start row, what are the cells that could be reached on the end\n",
    "# side ---> but you have to understand the rule of the game first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "75866337-aadb-405a-a4aa-da220c939236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LESS POSSIBLEE\n",
    "# given a binary tree, implement sibling (each nodes sibling is the next\n",
    "# node of the same depth). Each node has a point called sibling initialized to\n",
    "# null, implement a function such that all nodes' sibling pointer should have\n",
    "# proper value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f9ff6-0a52-482b-a8f9-205910f55c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5301c021-938f-4408-8131-e1c8fefb946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate an arithmetic expression that only involves multiplication and addition.\n",
    "\n",
    "# given an array of fruits, and another array of weights of fruits, write a function to pick the fruits randomly with a probabilityy distribution equal to its weights\n",
    "\n",
    "# given a graph and a nodde in the graph, return a deep copy of the node\n",
    "\n",
    "# given a frequency distribution of objects, write a random object generator which produces objects based on their probability distribution\n",
    "\n",
    "# level order transversal of a tree, \n",
    "# then make different between a shallow vs. deep copy\n",
    "\n",
    "# Given 1 billion data point (key, value with 15 bytes of string and 8 byte\n",
    "# of double value); store this in the memory that supports fast lookup.\n",
    "\n",
    "\n",
    "# Fraudulent user detection, find weakly connected component in large graph\n",
    "# (100k nodes, single machine). This question needs to be compiled and run on\n",
    "# a mac.\n",
    "\n",
    "# Given a binary search tree, find least common ancestor.\n",
    "\n",
    "#  Given a binary tree with parent pointers (pointers that direct from leaves to the root), design an\n",
    "# O(1) space complexity algorithm to find the lowest common ancestor of any two nodes.\n",
    "\n",
    "\n",
    "# Evaluate an arithmetic expression that only involves multiplication and addition.\n",
    "\n",
    "# PopulationNext right pointers in each node II\n",
    "\n",
    "# given a binary tree, implement sibling (each nodes sibling is the next\n",
    "# node of the same depth). Each node has a point called sibling initialized to\n",
    "# null, implement a function such that all nodes' sibling pointer should have\n",
    "# proper value.\n",
    "\n",
    "# TwoSum problem\n",
    "\n",
    "# do wordbreak\n",
    "# one way is to use \"dp\" to do it\n",
    "# another less ideal way is \"backtracking\"\n",
    "\n",
    "\n",
    "# how to optimized an sorted array\n",
    "\n",
    "\n",
    "# given a string, or a list of string items, see if they can be seperated to identify the Chemical elements eg. Na, Cl, Fe, Li\n",
    "# also given a list of all chemical elements string items\n",
    "# - recursive\n",
    "# dp?\n",
    "\n",
    "\n",
    "# Given a string, check if it could be decomposed into substring, which is\n",
    "# each an element symbol. physics => P H Y Si C S\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88117401-6e6f-4119-a448-e2018ae234df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff8ece-1d12-4e6b-9ef9-a0df3e22c785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaadd7f-b9e7-4648-8148-ee48afc15e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
